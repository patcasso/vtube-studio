import os
import asyncio
import websockets
import json
import time
import pygame
import librosa
import numpy as np
import aiohttp
import re
from dotenv import load_dotenv

# .env íŒŒì¼ì—ì„œ í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()
VTUBE_STUDIO_AUTH_TOKEN = os.environ.get("VTUBE_STUDIO_AUTH_TOKEN")
OPENAI_API_KEY = os.environ.get("OPENAI_API_KEY")
ELEVENLABS_API_KEY = os.environ.get("ELEVENLABS_API_KEY")
ELEVENLABS_VOICE_ID = os.environ.get("ELEVENLABS_VOICE_ID_OHW")  # OHW voice

# ì˜¤ë””ì˜¤ íŒŒì¼ ì €ì¥ ê²½ë¡œ
AUDIO_DIR = "./audio"
os.makedirs(AUDIO_DIR, exist_ok=True)

# OpenAI ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µì„ ìœ„í•œ í•¨ìˆ˜
async def stream_openai_response(messages):
    """OpenAI APIì—ì„œ ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µì„ ë°›ëŠ” í•¨ìˆ˜"""
    url = "https://api.openai.com/v1/chat/completions"
    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {OPENAI_API_KEY}",
    }
    data = {
        "model": "gpt-4.1",
        "messages": messages,
        "max_tokens": 300,
        "stream": True  # ìŠ¤íŠ¸ë¦¬ë° ëª¨ë“œ í™œì„±í™”
    }
    
    async with aiohttp.ClientSession() as session:
        async with session.post(url, headers=headers, json=data) as response:
            if response.status != 200:
                error_text = await response.text()
                print(f"Error from OpenAI API: {error_text}")
                yield "ì£„ì†¡í•©ë‹ˆë‹¤, ìš”ì²­ì„ ì²˜ë¦¬í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                return
            
            # ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ì²˜ë¦¬
            buffer = ""
            sentence_end_pattern = re.compile(r'[.!?]\s*')
            
            async for chunk in response.content:
                chunk_text = chunk.decode('utf-8')
                if chunk_text.startswith("data: ") and chunk_text.strip() != "data: [DONE]":
                    try:
                        # "data: " ì ‘ë‘ì‚¬ ì œê±°í•˜ê³  JSON íŒŒì‹±
                        json_str = chunk_text[6:]
                        chunk_data = json.loads(json_str)
                        # ë¸íƒ€ ì½˜í…ì¸  ì¶”ì¶œ
                        if "choices" in chunk_data and len(chunk_data["choices"]) > 0:
                            delta = chunk_data["choices"][0].get("delta", {})
                            if "content" in delta:
                                content = delta["content"]
                                buffer += content
                                
                                # ë¬¸ì¥ì´ ì™„ì„±ë˜ì—ˆëŠ”ì§€ í™•ì¸
                                match = sentence_end_pattern.search(buffer)
                                if match:
                                    sentence_end_idx = match.end()
                                    complete_sentence = buffer[:sentence_end_idx]
                                    buffer = buffer[sentence_end_idx:]
                                    
                                    # ì™„ì„±ëœ ë¬¸ì¥ ë°˜í™˜
                                    yield complete_sentence
                    except json.JSONDecodeError:
                        continue
                elif chunk_text.strip() == "data: [DONE]":
                    # ë‚¨ì€ í…ìŠ¤íŠ¸ê°€ ìˆìœ¼ë©´ ë°˜í™˜
                    if buffer.strip():
                        yield buffer.strip()
                    break


# TTS ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬ë¥¼ ìœ„í•œ í•¨ìˆ˜
async def stream_text_to_speech(text, index=0):
    """í…ìŠ¤íŠ¸ë¥¼ ìŒì„±ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜"""
    url = f"https://api.elevenlabs.io/v1/text-to-speech/{ELEVENLABS_VOICE_ID}/stream"
    headers = {
        "Accept": "audio/mpeg",
        "Content-Type": "application/json",
        "xi-api-key": ELEVENLABS_API_KEY,
    }
    data = {
        "text": text,
        "model_id": "eleven_multilingual_v2",
        "voice_settings": {"stability": 0.5, "similarity_boost": 0.75},  # ìŠ¤íŠ¸ë¦¬ë°ì— ìµœì í™”ëœ ì„¤ì •
    }
    
    tts_start_time = time.time()
    print(f"ë¬¸ì¥ {index}: TTS ë³€í™˜ ì‹œì‘...")
    
    async with aiohttp.ClientSession() as session:
        async with session.post(url, headers=headers, json=data) as response:
            if response.status == 200:
                # ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µì„ íŒŒì¼ë¡œ ì €ì¥
                audio_path = f"{AUDIO_DIR}/output_{index}.mp3"
                with open(audio_path, "wb") as f:
                    async for chunk in response.content.iter_chunked(1024):
                        f.write(chunk)
                
                tts_end_time = time.time()
                print(f"ë¬¸ì¥ {index}: TTS ì²˜ë¦¬ ì™„ë£Œ ({tts_end_time - tts_start_time:.2f}ì´ˆ)")
                return audio_path
            else:
                error_text = await response.text()
                print(f"Error from ElevenLabs API: {error_text}")
                return None


# ë¦½ì‹±í¬ë¥¼ ìœ„í•œ ì˜¤ë””ì˜¤ ë¶„ì„ í•¨ìˆ˜
def analyze_audio(audio_file_path):
    """ì˜¤ë””ì˜¤ íŒŒì¼ì„ ë¶„ì„í•˜ì—¬ íƒ€ì´ë°ê³¼ ì… ì›€ì§ì„ ê°’ì„ ë°˜í™˜"""
    # ì˜¤ë””ì˜¤ ë¡œë“œ
    y, sr = librosa.load(audio_file_path)
    
    # RMS ì—ë„ˆì§€ ê³„ì‚°
    hop_length = 512
    frame_length = 2048
    rms = librosa.feature.rms(y=y, frame_length=frame_length, hop_length=hop_length)[0]
    
    # ê° í”„ë ˆì„ì˜ ì‹œê°„ ê³„ì‚°
    times = librosa.times_like(rms, sr=sr, hop_length=hop_length)
    
    # RMS ê°’ì„ 0-1 ë²”ìœ„ë¡œ ì •ê·œí™”í•˜ê³  ì… ì›€ì§ì„ ê°’ìœ¼ë¡œ ë³€í™˜
    normalized_rms = np.interp(rms, (0, rms.max()), (0, 1))
    mouth_values = normalized_rms * 3
    
    return times, mouth_values


# ë³‘ë ¬ ì²˜ë¦¬ë¥¼ ìœ„í•œ ë©”ì¸ ëŒ€í™” í•¨ìˆ˜
async def parallel_chat_with_character(websocket):
    """ìŠ¤íŠ¸ë¦¬ë° ë°©ì‹ìœ¼ë¡œ ëŒ€í™”í•˜ëŠ” í•¨ìˆ˜"""
    # ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™”
    conversation_history = [
        {"role": "system", "content": "ë‹¹ì‹ ì€ ì¹œì ˆí•œ ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤."}
    ]
    
    while True:
        print("\nğŸ’¬ ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš” ('exit'ë¥¼ ì…ë ¥í•˜ë©´ ë©”ë‰´ë¡œ ëŒì•„ê°‘ë‹ˆë‹¤):")
        user_input = input("> ")
        
        if user_input.lower() == "exit":
            return
        
        total_start_time = time.time()
        
        # ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ ëŒ€í™” ê¸°ë¡ì— ì¶”ê°€
        conversation_history.append({"role": "user", "content": user_input})
        
        # ì˜¤ë””ì˜¤ íì™€ ì¬ìƒ ìƒíƒœë¥¼ ê´€ë¦¬í•˜ê¸° ìœ„í•œ ë³€ìˆ˜ë“¤
        audio_queue = asyncio.Queue()
        stop_event = asyncio.Event()
        
        # ìƒì„±ëœ ëª¨ë“  ì‘ë‹µ í…ìŠ¤íŠ¸ë¥¼ ì €ì¥í•  ë³€ìˆ˜
        full_response = ""
        
        # 1. ì˜¤ë””ì˜¤ ì¬ìƒ ë° ë¦½ì‹±í¬ ì²˜ë¦¬ íƒœìŠ¤í¬
        async def process_audio_queue():
            sentence_index = 0
            while not stop_event.is_set() or not audio_queue.empty():
                try:
                    # íì—ì„œ ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ ê°€ì ¸ì˜¤ê¸° (1ì´ˆ íƒ€ì„ì•„ì›ƒ)
                    audio_path = await asyncio.wait_for(audio_queue.get(), 1.0)
                    
                    # ì˜¤ë””ì˜¤ ë¶„ì„ ë° ë¦½ì‹±í¬ ì²˜ë¦¬
                    print(f"ë¬¸ì¥ {sentence_index}: ì˜¤ë””ì˜¤ ë¶„ì„ ë° ë¦½ì‹±í¬ ì‹œì‘...")
                    sync_start_time = time.time()
                    
                    await play_audio_with_mouth_sync(websocket, audio_path)
                    
                    sync_end_time = time.time()
                    print(f"ë¬¸ì¥ {sentence_index}: ë¦½ì‹±í¬ ì¬ìƒ ì™„ë£Œ ({sync_end_time - sync_start_time:.2f}ì´ˆ)")
                    
                    # ì²˜ë¦¬ ì™„ë£Œ í‘œì‹œ
                    audio_queue.task_done()
                    sentence_index += 1
                    
                except asyncio.TimeoutError:
                    # íƒ€ì„ì•„ì›ƒ ë°œìƒì‹œ íê°€ ë¹„ì–´ìˆê³  ìƒì„±ì´ ì¤‘ë‹¨ë˜ì—ˆëŠ”ì§€ í™•ì¸
                    if stop_event.is_set() and audio_queue.empty():
                        break
                    continue
        
        # 2. OpenAIì—ì„œ ì‘ë‹µ ìŠ¤íŠ¸ë¦¬ë° ë° TTS ë³€í™˜ íƒœìŠ¤í¬
        async def stream_response():
            nonlocal full_response
            sentence_index = 0
            
            async for sentence in stream_openai_response(conversation_history):
                if sentence:
                    print(f"ë¬¸ì¥ {sentence_index} ìˆ˜ì‹ : {sentence}")
                    full_response += sentence
                    
                    # TTS ë³€í™˜ ë° ì˜¤ë””ì˜¤ íì— ì¶”ê°€
                    audio_path = await stream_text_to_speech(sentence, sentence_index)
                    if audio_path:
                        await audio_queue.put(audio_path)
                    
                    sentence_index += 1
            
            # ëª¨ë“  ì‘ë‹µ ì²˜ë¦¬ ì™„ë£Œ í‘œì‹œ
            stop_event.set()
            
            # ëŒ€í™” ê¸°ë¡ì— ì–´ì‹œìŠ¤í„´íŠ¸ ì‘ë‹µ ì¶”ê°€
            conversation_history.append({"role": "assistant", "content": full_response})
            print(f"\nì „ì²´ ì‘ë‹µ: {full_response}")
        
        # ë‘ íƒœìŠ¤í¬ë¥¼ ë™ì‹œì— ì‹¤í–‰
        await asyncio.gather(
            stream_response(),
            process_audio_queue()
        )
        
        # ì„ì‹œ ì˜¤ë””ì˜¤ íŒŒì¼ ì •ë¦¬
        for filename in os.listdir(AUDIO_DIR):
            if filename.startswith("output_"):
                os.remove(os.path.join(AUDIO_DIR, filename))
        
        # ì „ì²´ ì²˜ë¦¬ ì‹œê°„ ê³„ì‚° ë° í‘œì‹œ
        total_end_time = time.time()
        total_duration = total_end_time - total_start_time
        print(f"\nâ±ï¸ ì „ì²´ ì²˜ë¦¬ ì‹œê°„: {total_duration:.2f}ì´ˆ")


# ì˜¤ë””ì˜¤ ì¬ìƒ ë° ë¦½ì‹±í¬ í•¨ìˆ˜ (ê¸°ì¡´ í•¨ìˆ˜ ìµœì í™”)
async def play_audio_with_mouth_sync(websocket, audio_path):
    """ì˜¤ë””ì˜¤ë¥¼ ì¬ìƒí•˜ê³  ë¦½ì‹±í¬ë¥¼ ì²˜ë¦¬í•˜ëŠ” í•¨ìˆ˜"""
    # ì˜¤ë””ì˜¤ ë¶„ì„
    times, mouth_values = analyze_audio(audio_path)
    
    # MouthOpenAmount íŒŒë¼ë¯¸í„°ê°€ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸í•˜ê³  í•„ìš”í•˜ë©´ ìƒì„±
    creation_request = {
        "apiName": "VTubeStudioPublicAPI",
        "apiVersion": "1.0",
        "requestID": "ParamCreate_MouthOpenAmount",
        "messageType": "ParameterCreationRequest",
        "data": {
            "parameterName": "MouthOpenAmount",
            "explanation": "Controls the amount of mouth open from audio volume.",
            "min": 0,
            "max": 100,
            "defaultValue": 0,
        },
    }
    await send_api_request(creation_request, websocket, silent=True)
    
    # ì˜¤ë””ì˜¤ ì¬ìƒ ì¤€ë¹„
    pygame.mixer.init()
    sound = pygame.mixer.Sound(audio_path)
    
    # íƒ€ì´ë° ë³€ìˆ˜ ì„¤ì •
    frame_count = len(times)
    current_frame = 0
    
    # ì˜¤ë””ì˜¤ ì¬ìƒ ì‹œì‘
    sound.play()
    start_time = time.time()
    
    # ë©”ì¸ ë™ê¸°í™” ë£¨í”„
    while current_frame < frame_count:
        # ê²½ê³¼ ì‹œê°„ ê¸°ë°˜ í”„ë ˆì„ ê³„ì‚°
        elapsed_time = time.time() - start_time
        target_frame = 0
        
        # í˜„ì¬ ì‹œê°„ì— ë§ëŠ” í”„ë ˆì„ ì°¾ê¸°
        while target_frame < frame_count and times[target_frame] < elapsed_time:
            target_frame += 1
        
        if target_frame >= frame_count:
            break
        
        # ìƒˆ í”„ë ˆì„ìœ¼ë¡œ ì´ë™í•  ë•Œë§Œ ì—…ë°ì´íŠ¸
        if target_frame > current_frame:
            current_frame = target_frame
            mouth_value = mouth_values[current_frame]
            
            # ë” ëšœë ·í•œ ì›€ì§ì„ì„ ìœ„í•œ ìŠ¤ì¼€ì¼ë§
            scaled_value = min(mouth_value * 20, 100)
            
            # VTube Studioì— íŒŒë¼ë¯¸í„° ì „ì†¡
            api_request = {
                "apiName": "VTubeStudioPublicAPI",
                "apiVersion": "1.0",
                "requestID": "MouthSync",
                "messageType": "InjectParameterDataRequest",
                "data": {
                    "faceFound": True,
                    "mode": "set",
                    "parameterValues": [
                        {"id": "MouthOpenAmount", "value": scaled_value},
                    ],
                },
            }
            await send_api_request(api_request, websocket, silent=True)
        
        # ìš”ì²­ í­ì£¼ ë°©ì§€ë¥¼ ìœ„í•œ ì§§ì€ ëŒ€ê¸°
        await asyncio.sleep(0.01)
    
    # ì˜¤ë””ì˜¤ ì¬ìƒ ì™„ë£Œ ëŒ€ê¸°
    remaining_time = sound.get_length() - elapsed_time
    if remaining_time > 0:
        await asyncio.sleep(remaining_time)
    
    # ì… ë‹«ê¸° ìœ„ì¹˜ë¡œ ì¬ì„¤ì •
    reset_request = {
        "apiName": "VTubeStudioPublicAPI",
        "apiVersion": "1.0",
        "requestID": "ResetMouth",
        "messageType": "InjectParameterDataRequest",
        "data": {
            "faceFound": True,
            "mode": "set",
            "parameterValues": [
                {"id": "MouthOpenAmount", "value": 0},
            ],
        },
    }
    await send_api_request(reset_request, websocket, silent=True)


# VTube Studio API ìš”ì²­ ì „ì†¡ í•¨ìˆ˜
async def send_api_request(request, websocket, silent=False):
    """VTube Studio API ìš”ì²­ì„ ì „ì†¡í•˜ëŠ” í•¨ìˆ˜"""
    api_request_json = json.dumps(request)
    await websocket.send(api_request_json)
    response = await websocket.recv()
    if not silent:
        response_json = json.loads(response)
        print(json.dumps(response_json, indent=4))
        return response_json
    return json.loads(response)


# ì¸ì¦ í† í° ìš”ì²­ í•¨ìˆ˜
async def request_auth_token(websocket):
    """ì¸ì¦ í† í°ì„ ìš”ì²­í•˜ëŠ” í•¨ìˆ˜"""
    token_request = {
        "apiName": "VTubeStudioPublicAPI",
        "apiVersion": "1.0",
        "requestID": "TokenRequestID",
        "messageType": "AuthenticationTokenRequest",
        "data": {
            "pluginName": "VtsTestPlugin",
            "pluginDeveloper": "Patcasso",
        },
    }
    print("\nğŸ”‘ ì¸ì¦ í† í° ìš”ì²­ ì¤‘...")
    response = await send_api_request(token_request, websocket)
    
    if response["messageType"] == "AuthenticationTokenResponse":
        token = response["data"]["authenticationToken"]
        print(f"\nâœ… í† í° ìˆ˜ì‹ : {token}")
        return token
    elif response["messageType"] == "APIError":
        print(f"\nâŒ ì˜¤ë¥˜: {response['data']['message']}")
        return None
    else:
        print("\nâŒ ì˜ˆìƒì¹˜ ëª»í•œ ì‘ë‹µ.")
        return None


# í† í°ìœ¼ë¡œ ì¸ì¦ í•¨ìˆ˜
async def authenticate_with_token(websocket, token):
    """í† í°ìœ¼ë¡œ ì¸ì¦í•˜ëŠ” í•¨ìˆ˜"""
    auth_request = {
        "apiName": "VTubeStudioPublicAPI",
        "apiVersion": "1.0",
        "requestID": "AuthRequestID",
        "messageType": "AuthenticationRequest",
        "data": {
            "pluginName": "VtsTestPlugin",
            "pluginDeveloper": "Patcasso",
            "authenticationToken": token,
        },
    }
    print("\nğŸ” í† í°ìœ¼ë¡œ ì¸ì¦ ì¤‘...")
    response = await send_api_request(auth_request, websocket)
    
    if (
        response["messageType"] == "AuthenticationResponse"
        and response["data"]["authenticated"]
    ):
        print("\nâœ… í”ŒëŸ¬ê·¸ì¸ ì¸ì¦ ì„±ê³µ!")
        return True
    else:
        print("\nâŒ ì¸ì¦ ì‹¤íŒ¨.")
        return False


# ë©”ì¸ í•¨ìˆ˜
async def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    uri = "ws://localhost:8001"
    
    async with websockets.connect(uri) as websocket:
        print("1. ì…ë ¥ëœ í† í° ì‚¬ìš©")
        print("2. ìƒˆë¡œ í† í° ìš”ì²­ (íŒì—… ëœ¸)")
        token_option = input("ì„ íƒ (1/2): ")
        
        token = None
        if token_option == "1":
            token = VTUBE_STUDIO_AUTH_TOKEN
        elif token_option == "2":
            token = await request_auth_token(websocket)
        else:
            print("ì˜ëª»ëœ ì…ë ¥.")
            return
        
        if not token:
            print("í† í° ì—†ìŒ. ì¢…ë£Œ.")
            return
        
        authenticated = await authenticate_with_token(websocket, token)
        if not authenticated:
            return
        
        # ë©”ë‰´ ë£¨í”„
        while True:
            print("\n=== VTube Studio ì»¨íŠ¸ë¡¤ ë©”ë‰´ ===")
            print("1. API ìƒíƒœ ìš”ì²­")
            print("2. í˜„ì¬ ëª¨ë¸ ê°€ì ¸ì˜¤ê¸°")
            print("3. í˜„ì¬ ëª¨ë¸ì˜ ëª¨ë“  Live2D íŒŒë¼ë¯¸í„° ê°’ ê°€ì ¸ì˜¤ê¸°")
            print("4. ë³‘ë ¬ ì²˜ë¦¬ë¡œ ìºë¦­í„°ì™€ ëŒ€í™”í•˜ê¸°")  # ìƒˆë¡œìš´ ìŠ¤íŠ¸ë¦¬ë° ëŒ€í™” ì˜µì…˜
            print("5. í•˜íŠ¸ ëˆˆ ì¼œê¸°/ë„ê¸°")
            print("6. ëˆˆë¬¼ ì¼œê¸°/ë„ê¸°")
            print("7. í™”ë‚œ í‘œì‹œ ì¼œê¸°/ë„ê¸°")
            print("8. ë†€ë€ í‘œì‹œ ì¼œê¸°/ë„ê¸°")
            print("9. í”ë“¤ë¦¼ ì• ë‹ˆë©”ì´ì…˜ ì¼œê¸°/ë„ê¸°")
            print("0. ì¢…ë£Œ")
            
            choice = input("ì„ íƒí•˜ì„¸ìš” (0-9): ")
            
            if choice == "1":
                api_request = {
                    "apiName": "VTubeStudioPublicAPI",
                    "apiVersion": "1.0",
                    "requestID": "SomeID",
                    "messageType": "APIStateRequest",
                }
                await send_api_request(api_request, websocket)
            
            elif choice == "2":
                api_request = {
                    "apiName": "VTubeStudioPublicAPI",
                    "apiVersion": "1.0",
                    "requestID": "SomeID",
                    "messageType": "CurrentModelRequest",
                }
                await send_api_request(api_request, websocket)
            
            elif choice == "3":
                api_request = {
                    "apiName": "VTubeStudioPublicAPI",
                    "apiVersion": "1.0",
                    "requestID": "SomeID",
                    "messageType": "Live2DParameterListRequest",
                }
                await send_api_request(api_request, websocket)
            
            elif choice == "4":
                # ìƒˆë¡œìš´ ë³‘ë ¬ ì²˜ë¦¬ ëŒ€í™” í•¨ìˆ˜ í˜¸ì¶œ
                await parallel_chat_with_character(websocket)
            
            elif choice == "5":
                api_request = {
                    "apiName": "VTubeStudioPublicAPI",
                    "apiVersion": "1.0",
                    "requestID": "SomeID",
                    "messageType": "HotkeyTriggerRequest",
                    "data": {
                        "hotkeyID": "995d790e63e940e78b43b717ef214756",
                    },
                }
                await send_api_request(api_request, websocket)
            
            elif choice == "6":
                api_request = {
                    "apiName": "VTubeStudioPublicAPI",
                    "apiVersion": "1.0",
                    "requestID": "SomeID",
                    "messageType": "HotkeyTriggerRequest",
                    "data": {
                        "hotkeyID": "ac728f4052064ae6b05c58e9290167f9",
                    },
                }
                await send_api_request(api_request, websocket)
            
            elif choice == "7":
                api_request = {
                    "apiName": "VTubeStudioPublicAPI",
                    "apiVersion": "1.0",
                    "requestID": "SomeID",
                    "messageType": "HotkeyTriggerRequest",
                    "data": {
                        "hotkeyID": "23b57c8036f240779608c9d246c7716c",
                    },
                }
                await send_api_request(api_request, websocket)
            
            elif choice == "8":
                api_request = {
                    "apiName": "VTubeStudioPublicAPI",
                    "apiVersion": "1.0",
                    "requestID": "SomeID",
                    "messageType": "HotkeyTriggerRequest",
                    "data": {
                        "hotkeyID": "8050ec17c3ee41a1b824ee1815407022",
                    },
                }
                await send_api_request(api_request, websocket)
            
            elif choice == "9":
                api_request = {
                    "apiName": "VTubeStudioPublicAPI",
                    "apiVersion": "1.0",
                    "requestID": "SomeID",
                    "messageType": "HotkeyTriggerRequest",
                    "data": {
                        "hotkeyID": "0415de2ef49e4943a9bfbe5dfeda3452",
                    },
                }
                await send_api_request(api_request, websocket)
            
            elif choice == "0":
                print("í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                break
            
            else:
                print("ì˜ëª»ëœ ì„ íƒì…ë‹ˆë‹¤. 0ë¶€í„° 9 ì‚¬ì´ì˜ ìˆ«ìë¥¼ ì…ë ¥í•˜ì„¸ìš”.")


if __name__ == "__main__":
    asyncio.get_event_loop().run_until_complete(main())